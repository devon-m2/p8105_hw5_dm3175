---
title: "p8105_hw5_dm3175"
author: "Devon Morgan"
date: "11/5/2018"
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(purrr)

```

# Problem 1

## Load and Clean Data

First, the data from the longitudinal study was loaded and cleaned. The files were originally stored in separate csv files, but were loaded and combined into one dateframe using the `map` function. The `map` functionality iterates over the cells in the file name column to carry out the `read_csv` function, and enters the output into a new column in the data frame. Data was unnested after it was read in. 

Next, data was tidied using the `gather` function to organize all observations by week of observation. Using the information stored in the file name, columns for the `subject_id` and `week` were created. The `group_arm` variable was converted into a factor variable, and the `subject_id` and `week` into numeric. 

```{r message = FALSE}
# Load list of file names into a data frame
longit_file_names = tibble(files = list.files("./data"),
                           path = str_c("./data/", files)) %>% 
  janitor::clean_names() 

# Iterate loading csvs from directory and tidy data
longit_tidy = longit_file_names %>% 
  mutate(patient_data = map(path, read_csv)) %>% 
  unnest() %>% 
  gather(key = week, value = obs, week_1:week_8) %>% 
  separate(files, into = c("group_arm", "subject_id"), sep = "_") %>% 
  mutate(subject_id = str_replace(subject_id, ".csv", ""), 
         week = str_replace(week, "week_", "")) %>% 
  mutate(group_arm = factor(group_arm, levels = c("con", "exp")),
         subject_id = as.double(subject_id), 
         week = as.double(week)) %>% 
  select(group_arm, subject_id, week, obs)

```

## Spaghetti Plot of All Subjects Over Time

A spaghetti plot of all subjects from control and experimental groups over time reveals that control group observations are consistently lower than experimental group observations over time. The differences appear to be diverging more over time, with earlier time points showing more overlap between the groups and later time points showing greater differences. The observation values for the experimental group appears to be increasing over time.

```{r}
longit_tidy %>% 
  group_by(subject_id, group_arm) %>% 
  ggplot(aes(x = week, y = obs, color = group_arm, group = interaction(subject_id, group_arm))) + 
  geom_line(se = FALSE) +
  labs(
    title = "Observations for Each Subject in Control and Experimental Groups, Weeks 1-8",
    x = "Week",
    y = "Observation",
    caption = "Data from the Longitudinal Study"
  ) + 
  theme_bw()

```

# Problem 2

## Load and Clean the Data

The next problem explores data gathered by the Washington Post on homicides in 50 large US cities. Data was read in from a CSV posted on GitHub.

```{r}
url = "https://raw.githubusercontent.com/washingtonpost/data-homicides/master/homicide-data.csv"
homicide_data = read_csv(url, na = "Unknown") %>% 
  janitor::clean_names() 

# Clean error in state "AL" to "OK" for Tul-000769
clean_homicide_data = homicide_data %>% 
  mutate(state = ifelse(uid == "Tul-000769", "OK", state)) %>% 
  mutate(city_state = str_c(city, ", ", state))

```

The dataset contains `r nrow(homicide_data)` observations and `r ncol(homicide_data)` variables. A new variable `city_state` was created to concatenate the city and state variables. The variables in the dataset are: 

*  `uid` - unique identifier
*  `reported_date` - date homicide reported
*  `victim_last` and `victim_first` - name of victim
*  `victim_race` - race of victim
*  `victim_age` - age of victim
*  `victim_sex` - sex of victim
*  `city` - city of homicide
*  `state` - state of homicide
*  `city_state` - combination city, state
*  `lat` and `lon` - latitude and longitude of homicide
*  `disposition` - outcome of homicide with three options: "Closed by arest", "Closed without arrest", or "Open/No arrest"

An error in the original data table listed "Tulsa, AL" as a location; however, the coordinates actually corresponded to "Tulsa, OK". Therefore, the state was fixed to Oklahoma in the clean dataset.  

## Homicides by City, State

### Total Homicides and Unsolved Homicides in All Cities
The total number of homicides and unsolved homicides for each city, state is provided in the table below. 

```{r}
total_hom_count = clean_homicide_data %>% 
  group_by(city_state) %>% 
  summarize(n_total_homicides = n())

unsolved_hom_count = clean_homicide_data %>% 
  filter(disposition == "Closed without arrest" | disposition == "Open/No arrest") %>% 
  group_by(city_state) %>% 
  summarize(n_unsolved_homicide = n())

homicide_counts = full_join(total_hom_count, unsolved_hom_count, by = "city_state") %>% 
  arrange(desc(n_total_homicides))

homicide_counts %>% 
  knitr::kable(digits = 1)
```

Chicago, IL, Philadelphia, PA, and Houston, TX are the top three cities by total homicides. The table also presents the total number of unsolved homicides (those with disposition of “Closed without arrest” or “Open/No arrest”). Chicago, IL had the largest number of unsolved homicides with `r filter(homicide_counts, city_state == "Chicago, IL") %>% pull(n_unsolved_homicide)`. Baltimore, MD has the second largest number of unsolved homicides with `r filter(homicide_counts, city_state == "Baltimore, MD") %>% pull(n_unsolved_homicide)`. The city with the least unsolved homicides was Tampa, FL with `r filter(homicide_counts, city_state == "Tampa, FL") %>% pull(n_unsolved_homicide)`. Tulsa, AL had no unsolved homicides reported. 

### Unsolved Homicides in Baltimore, MD

One sample test of the proportion of unsolved homicides in Baltimore, MD using `prop.test`: 
```{r}
baltimore_prop = prop.test(x = filter(homicide_counts, city_state == "Baltimore, MD") %>% pull(n_unsolved_homicide), 
          n = filter(homicide_counts, city_state == "Baltimore, MD") %>% pull(n_total_homicides)) %>% 
  broom::tidy()
    
baltimore_prop %>% select(estimate, conf.low, conf.high) %>% knitr::kable(digits = 5)

```


### Unsolved Homicides in All Cities

Next, the proportion tests were carried out for the proportion of unsolved homicides for all cities.  
```{r}
homicide_counts %>% 
  mutate(prop_test = map2(.x = n_unsolved_homicide, .y = n_total_homicides, ~prop.test(x = .x, n = .y))) %>%
  mutate(prop_test = map(prop_test, broom::tidy)) %>% 
  unnest() %>% 
  select(city_state, estimate, conf.low, conf.high)

        


```



